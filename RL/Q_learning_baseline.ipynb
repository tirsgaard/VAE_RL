{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define replay buffer\n",
    "class replay_buffer:\n",
    "    def __init__(self, n_stored, S_size, n_phi):\n",
    "        self.D = np.empty(n_stored, dtype='object')\n",
    "        self.counter = 0\n",
    "        self.max_capacity = n_stored\n",
    "        self.S_size = S_size\n",
    "        self.n_phi = n_phi\n",
    "        \n",
    "    def add_replay(self, replay):\n",
    "\n",
    "        if (self.max_capacity>=self.counter):\n",
    "            # Case where added there is room for replays\n",
    "            self.D[self.counter] = replay\n",
    "            self.counter += 1\n",
    "        else:\n",
    "            # Case where a replay has to be supstituted\n",
    "            replace_index = np.random.randint(self.max_capacity)\n",
    "            self.D[replace_index] = replay\n",
    "    \n",
    "    def return_batch(self, batch_size):\n",
    "        # Get index for batch\n",
    "        indexes = np.random.randint(self.counter, size=batch_size)\n",
    "        batch = self.D[indexes]\n",
    "        \n",
    "        # Define arrays for return\n",
    "        S_array = np.zeros((batch_size,)+ (self.n_phi,) + self.S_size)\n",
    "        S_next_array = np.zeros((batch_size,) + (self.n_phi,) + self.S_size)\n",
    "        a_array = np.zeros(batch_size)\n",
    "        r_array = np.zeros(batch_size)\n",
    "        \n",
    "        # Fill the batch\n",
    "        i = 0\n",
    "        for S, a, r, S_next in batch:\n",
    "            S_array[i] = S\n",
    "            a_array[i] = a\n",
    "            r_array[i] = r\n",
    "            S_next_array[i] = S_next\n",
    "            i += 1\n",
    "            \n",
    "        return S_array, a_array, r_array, S_next_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model\n",
    "class model:\n",
    "    def __init__(self, S_size, n_actions, n_phi):\n",
    "        # The classification network based on the transformed (cropped) image\n",
    "        filter1_size = 32\n",
    "        filter2_size = 64\n",
    "        filter3_size = 64\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1,\n",
    "                               out_channels=filter1_size,\n",
    "                               kernel_size=8,\n",
    "                               stride=4,\n",
    "                               padding=4)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=filter1_size, \n",
    "                               out_channels=filter2_size,\n",
    "                               kernel_size=4,\n",
    "                               stride=2,\n",
    "                               padding=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=filter2_size, \n",
    "                               out_channels=filter3_size,\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=2)\n",
    "        \n",
    "        # fully connected output layers\n",
    "        self.fc1 = nn.Linear(in_features=50176, \n",
    "                             out_features=n_actions)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten input\n",
    "        #x = x.astype(\"float\")\n",
    "        x = torch.from_numpy(x)\n",
    "        #x = x.float()\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        \n",
    "        x = x.view(-1)\n",
    "        \n",
    "        # Pass input\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "# Define transformer of image\n",
    "def phi_transformer(S, n_phi):\n",
    "    pre_process = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToPILImage(),\n",
    "     torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "     torchvision.transforms.Resize([84,84]),\n",
    "     torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize(mean=[0.], std=[1.])])\n",
    "\n",
    "    lists = []\n",
    "    for i in range(n_phi):\n",
    "        lists.append(pre_process(S[i]))\n",
    "        \n",
    "    S = torch.stack(lists)\n",
    "    return S.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Riverraid-v0')\n",
    "env.reset()\n",
    "S_size = 4\n",
    "n_phi = 4\n",
    "n_actions = 2\n",
    "buffer_size = 10**6\n",
    "update_freq = 1000\n",
    "Q_network = model(S_size, n_actions, n_phi)\n",
    "Q_target = model(S_size, n_actions, n_phi)\n",
    "buffer = replay_buffer(buffer_size, S_size, n_phi)\n",
    "epsilon = 0.1\n",
    "n_games = 100\n",
    "gamma = 0.99\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define some usefull values\n",
    "a_space = env.action_space.n\n",
    "S_space = env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "uint8\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate tuple (not \"int\") to tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-710abd00d974>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m## Perform update of Q_network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mS_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_next_train\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0my_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_train\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_next_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQ_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-d5b15ca0d8b0>\u001b[0m in \u001b[0;36mreturn_batch\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Define arrays for return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mS_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_phi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mS_next_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_phi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0ma_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate tuple (not \"int\") to tuple"
     ]
    }
   ],
   "source": [
    "### Prepare environments\n",
    "\n",
    "for i in range(n_games):\n",
    "    # Restart environment\n",
    "    # Reset observation\n",
    "    S = np.zeros((n_phi,) + S_space, dtype=\"uint8\")\n",
    "    S_next = np.zeros((n_phi,) + S_space, dtype=\"uint8\")\n",
    "    S[n_phi-1] = env.reset()\n",
    "    done = False\n",
    "    S = phi_transformer(S,n_phi) # Transform input\n",
    "    \n",
    "    while not done:\n",
    "        ## Select random or non-random action\n",
    "        if np.random.rand(1)[0]<epsilon:\n",
    "            # Case ranom move selected\n",
    "            a = np.random.randint(a_space)\n",
    "        else:\n",
    "            # Case non-random move\n",
    "            with torch.no_grad():\n",
    "                a = np.argmax(Q_network.forward(S).numpy())\n",
    "\n",
    "        # Perform action for n_phi times\n",
    "        r = 0\n",
    "        for j in range(n_phi):\n",
    "            S_next[j], r_temp, done, info = env.step(a)\n",
    "            r += r_temp\n",
    "\n",
    "            if (done): # Check if game done\n",
    "                # Have to save process S_next\n",
    "                S_next[(n_phi-j):n_phi] = S_next[0:j]\n",
    "                S_next[0:(n_phi-j)] = S[j:n_phi]\n",
    "                break\n",
    "        S_next = phi_transformer(S_next, n_phi) # Transform input\n",
    "        # Store data\n",
    "        replay = [S, a, r, S_next]\n",
    "        buffer.add_replay(replay)\n",
    "        S = S_next # Switch state\n",
    "        \n",
    "        ## Perform update of Q_network\n",
    "        [S_train, a_train, r_train, S_next_train] = buffer.return_batch(batch_size)\n",
    "        y_target = r_train + np.argmax(Q_target.forward(S_next_train))\n",
    "        y_train = Q_network.forward(S_train)\n",
    "        batch_loss = criterion(y_target,y_train)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update target_Q\n",
    "        if (i % update_freq == 0):\n",
    "            target_Q = Q_network.copy()\n",
    "            target_Q.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "S, r_temp, done, info = env.step(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [170, 170, 170],\n",
       "        [170, 170, 170],\n",
       "        [170, 170, 170]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-0.03398085,  0.02914684,  0.01451927, -0.04932675]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.astype(\"double\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((5))[np.random.randint(5,size=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
